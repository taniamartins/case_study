{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91bea712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66eff12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"data/survival_dataset.csv\") #training set\n",
    "df_pred = pd.read_csv(\"data/survival_predict.csv\") #prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "107bc289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in train but not in pred:\n",
      "{'duration', 'event'}\n",
      "Columns in pred but not in train:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Columns only in training set\n",
    "print(\"Columns in train but not in pred:\")\n",
    "print(set(df.columns) - set(df_pred.columns))\n",
    "\n",
    "# Columns only in prediction set\n",
    "print(\"Columns in pred but not in train:\")\n",
    "print(set(df_pred.columns) - set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce318ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "df_cox = pd.get_dummies(df, columns=[\"sector\", \"location\", \"purpose\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df74d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 5000 total observations, 3191 right-censored observations>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Cox model\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_cox, duration_col=\"duration\", event_col=\"event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61feff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "with open(\"models/survival_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "718916cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess: must match training features exactly!\n",
    "# → same encoding, scaling, dummy variables, etc.\n",
    "feature_cols = df_cox.drop(columns=[\"duration\", \"event\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5320c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode using same logic\n",
    "df_pred_encoded = pd.get_dummies(df_pred, columns=[\"sector\", \"location\", \"purpose\"], drop_first=True)\n",
    "\n",
    "# Align columns with training\n",
    "df_pred_encoded = df_pred_encoded.reindex(columns=feature_cols, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f2d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VIZ\n",
    "\n",
    "os.makedirs(\"figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c04f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the common columns shared between both datasets\n",
    "common_cols = df_cox.columns.intersection(df_pred_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09e6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in common_cols:\n",
    "    try:\n",
    "        # Drop NA values\n",
    "        train_vals = df_cox[col].dropna()\n",
    "        pred_vals = df_pred_encoded[col].dropna()\n",
    "\n",
    "        # Skip low-variance columns\n",
    "        if train_vals.nunique() <= 1 and pred_vals.nunique() <= 1:\n",
    "            print(f\"⚠️ Skipping {col} due to low variance.\")\n",
    "            continue\n",
    "\n",
    "        # Combine for plotting\n",
    "        df_plot = pd.concat([\n",
    "            pd.DataFrame({col: train_vals, \"Dataset\": \"Train\"}),\n",
    "            pd.DataFrame({col: pred_vals, \"Dataset\": \"Prediction\"})\n",
    "        ])\n",
    "\n",
    "        # Plot side-by-side histograms (faceted by dataset)\n",
    "        g = sns.displot(\n",
    "            data=df_plot,\n",
    "            x=col,\n",
    "            col=\"Dataset\",\n",
    "            bins=20,\n",
    "            kde=False,\n",
    "            stat=\"density\",\n",
    "            common_bins=True,\n",
    "            facet_kws={\"sharey\": False, \"sharex\": True},\n",
    "            height=4,\n",
    "            aspect=1.2\n",
    "        )\n",
    "        g.fig.suptitle(f\"Histogram of {col} by Dataset\", fontsize=14)\n",
    "        g.fig.tight_layout()\n",
    "        g.fig.subplots_adjust(top=0.85)\n",
    "\n",
    "        # Save\n",
    "        filename = f\"figures/facet_hist_{col}.png\".replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        g.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {col} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359f9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/survival_model.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb2a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "survival_probs = []\n",
    "for idx, row in df_pred_encoded.iterrows():\n",
    "    term = df_pred_encoded.loc[idx, \"term_months\"]\n",
    "    surv_func = cph.predict_survival_function(row.to_frame().T)\n",
    "    prob = surv_func.loc[term].values[0] if term in surv_func.index else surv_func.iloc[-1].values[0]\n",
    "    survival_probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84300310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to dataset\n",
    "df_pred[\"survival_probability\"] = survival_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save or pass to credit risk model\n",
    "df_pred.to_csv(\"data/scored_survival_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
